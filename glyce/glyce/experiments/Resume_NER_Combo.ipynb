{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resume_NER_Combo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z2Id0h3kTG5F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"52c40a64-e0d4-450a-b330-5c781f5c954d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5db9491b-4bc3-4740-cefa-04843f320eb7"},"source":["!pip install pypinyin pywubi zhconv overrides boto3\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 92.3 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 85.6 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.26-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 89.6 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting botocore<1.22.0,>=1.21.26\n","  Downloading botocore-1.21.26-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 57.5 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.7 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.26->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.26->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181081 sha256=f562cb3732809f848d64abcd3af0f667d1bca7f3d4ff5337f53dc72179602e2a\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.26 botocore-1.21.26 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-scatter\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 1.4 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.8\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-sparse\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 15.8 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.11\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-cluster\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n","\u001b[K     |████████████████████████████████| 926 kB 4.1 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-spline-conv\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n","\u001b[K     |████████████████████████████████| 382 kB 4.3 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 28.4 MB/s \n","\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Collecting isodate\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 77.6 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=bac31bb67aa47481737798c136c0e0bfdfe8da305d865407f505e66dd55d5a22\n","  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n","Successfully built torch-geometric\n","Installing collected packages: urllib3, isodate, rdflib, torch-geometric\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2 urllib3-1.25.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Oob8oexy_N4","outputId":"f89fbda6-cb43-4e2c-d5d2-93764254c657"},"source":["import time\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"391323e5-f94a-45b4-827e-5f30f5af2870"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_combo_tagger.py\" \\\n","--data_sign resume_ner \\\n","--task_name ner \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/combo_bert.json\" \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/ner/resume\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/resume_ner combo.bin\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--graph_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\" \\\n","--checkpoint 160 \\\n","--seed 8008 \\\n","--max_seq_length 150 \\\n","--do_train \\\n","--do_eval \\\n","--train_batch_size 24 \\\n","--dev_batch_size 24 \\\n","--test_batch_size 24 \\\n","--learning_rate 3e-5 \\\n","--num_train_epochs 15 \\\n","--gcn_hidden 300 \\\n","--k 30 \\\n","--num_features 6 \\\n","--warmup_proportion 0 \\\n","--batch_norm \"layer\" \\\n","--pretrained_graph \"yes\" \\\n","--graph_dict \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\" \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 888,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"multi_nonlinear\",\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"glyph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"cnn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"glyph_cnn_type\": \"Yuxian8\",\n","    \"glyph_embsize\": 96,\n","    \"glyph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 96,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"font_names\": []\n","  },\n","  \"graph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"graph_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"gcn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"num_features\": 6,\n","    \"gcn_hidden\": 300,\n","    \"k\": 30,\n","    \"gcn_layer\": \"SAGE\",\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"graph_cnn_type\": \"Yuxian8\",\n","    \"graph_embsize\": 24,\n","    \"graph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 24,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"pool\": \"sort\",\n","    \"graph_dict\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\",\n","    \"pretrained_graph\": \"yes\",\n","    \"batch_norm\": \"layer\"\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 888,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3552,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 888,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/combo_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/ner/resume\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"ner\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 150,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 24,\n","  \"dev_batch_size\": 24,\n","  \"checkpoint\": 160,\n","  \"test_batch_size\": 24,\n","  \"learning_rate\": 3e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/resume_ner combo/real_1.bin\",\n","  \"data_sign\": \"resume_ner\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\",\n","  \"transformer\": \"yes\"\n","}\n","3821it [00:01, 3365.36it/s]\n","463it [00:00, 4358.68it/s]\n","477it [00:00, 3944.84it/s]\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","159it [02:06,  1.27it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.01507270336151123 12.848918914794922\n","100% 20/20 [00:14<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0221 0.9013 0.9092 0.9052 0.9732\n","100% 20/20 [00:14<00:00,  1.37it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0286 0.9108 0.8968 0.9037 0.97\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:37,  1.02it/s]\n","######################################################################\n","EPOCH:  1\n","159it [02:04,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.01691167615354061 11.363604545593262\n","100% 20/20 [00:13<00:00,  1.43it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0154 0.9405 0.9405 0.9405 0.9818\n","100% 20/20 [00:14<00:00,  1.37it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0212 0.9559 0.9459 0.9509 0.978\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:35,  1.03it/s]\n","######################################################################\n","EPOCH:  2\n","159it [02:04,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00047780791646800935 11.650936126708984\n","100% 20/20 [00:14<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0178 0.9407 0.9439 0.9423 0.9804\n","100% 20/20 [00:14<00:00,  1.40it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0275 0.9554 0.9472 0.9513 0.9764\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:34,  1.03it/s]\n","######################################################################\n","EPOCH:  3\n","159it [02:04,  1.29it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0006593071739189327 11.181525230407715\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0211 0.9461 0.9499 0.948 0.9827\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0306 0.9571 0.9453 0.9512 0.9769\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:35,  1.03it/s]\n","######################################################################\n","EPOCH:  4\n","159it [02:04,  1.29it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00039056228706613183 11.135143280029297\n","100% 20/20 [00:14<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0242 0.945 0.9532 0.9491 0.9799\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.027 0.9599 0.9545 0.9572 0.9831\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:34,  1.03it/s]\n","\n","Training Combo...\n","######################################################################\n","EPOCH:  5\n","159it [01:34,  1.70it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00043451887904666364 12.211523056030273\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0232 0.9457 0.9546 0.9501 0.9798\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0273 0.9592 0.9539 0.9566 0.9833\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:04,  1.28it/s]\n","######################################################################\n","EPOCH:  6\n","159it [01:33,  1.71it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0002886138390749693 12.498334884643555\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0231 0.947 0.9546 0.9508 0.98\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0274 0.9605 0.9558 0.9581 0.9841\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:04,  1.28it/s]\n","######################################################################\n","EPOCH:  7\n","159it [01:34,  1.70it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0002505051961634308 12.19250202178955\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0249 0.947 0.9546 0.9508 0.98\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:48,  1.47it/s]\n","######################################################################\n","EPOCH:  8\n","159it [01:33,  1.71it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0002803387469612062 12.496752738952637\n","100% 20/20 [00:13<00:00,  1.43it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0256 0.947 0.9546 0.9508 0.98\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:48,  1.48it/s]\n","######################################################################\n","EPOCH:  9\n","159it [01:33,  1.69it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0001578715891810134 13.370553016662598\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0236 0.947 0.9546 0.9508 0.9801\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0283 0.9592 0.9539 0.9566 0.9833\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:02,  1.30it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","159it [02:15,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00016898676403798163 13.451857566833496\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0242 0.943 0.9506 0.9468 0.98\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:29,  1.07it/s]\n","######################################################################\n","EPOCH:  11\n","159it [02:15,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00020195799879729748 13.708394050598145\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0255 0.9417 0.9492 0.9454 0.979\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:29,  1.07it/s]\n","######################################################################\n","EPOCH:  12\n","159it [02:15,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00029227009508758783 13.185419082641602\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0258 0.9445 0.9546 0.9495 0.9805\n","100% 20/20 [00:14<00:00,  1.37it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0313 0.9581 0.9558 0.9569 0.9834\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:44,  1.03s/it]\n","######################################################################\n","EPOCH:  13\n","159it [02:15,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","7.725573959760368e-05 13.481764793395996\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0263 0.9439 0.9546 0.9492 0.9807\n","100% 20/20 [00:14<00:00,  1.39it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0316 0.9569 0.9558 0.9564 0.9835\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:44,  1.03s/it]\n","######################################################################\n","EPOCH:  14\n","159it [02:15,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00017832531011663377 13.495434761047363\n","100% 20/20 [00:14<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0289 0.9439 0.9546 0.9492 0.9807\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:29,  1.07it/s]\n","100% 20/20 [00:14<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0317 0.9575 0.9558 0.9567 0.9835\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.0263 0.9439 0.9546 0.9492 0.9807\n","TEST: current best loss, precision, recall, f1, acc\n","0.0274 0.9605 0.9558 0.9581 0.9841\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28d29f70-72a7-41ac-a0d8-59ddcb9175e3"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 00:38:03\n"],"name":"stdout"}]}]}